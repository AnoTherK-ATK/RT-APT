{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T16:14:13.248509Z",
     "start_time": "2025-06-22T16:14:12.200460Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import networkx as nx\n",
    "from collections import Counter, deque\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import random as rd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T16:15:02.388087Z",
     "start_time": "2025-06-22T16:14:15.998867Z"
    }
   },
   "cell_type": "code",
   "source": "graphs, labels = joblib.load(\"graphs_and_labels.joblib\")",
   "id": "44d10d3139873798",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class FlexSketch:\n",
    "    def __init__(self, max_bins=100, max_histograms=5):\n",
    "        self.max_bins = max_bins\n",
    "        self.max_histograms = max_histograms\n",
    "        self.histograms = deque()\n",
    "        self.weights = deque()\n",
    "\n",
    "    def update(self, label_counter):\n",
    "        most_common = label_counter.most_common(self.max_bins)\n",
    "        vector = np.zeros(self.max_bins)\n",
    "        for i, (_, count) in enumerate(most_common):\n",
    "            vector[i] = count\n",
    "        self.histograms.append(vector)\n",
    "        self.weights.append(1.0)\n",
    "        if len(self.histograms) > self.max_histograms:\n",
    "            self.histograms.popleft()\n",
    "            self.weights.popleft()\n",
    "        total_weight = sum(self.weights)\n",
    "        self.weights = deque([w / total_weight for w in self.weights])\n",
    "\n",
    "    def estimate_vector(self):\n",
    "        result = np.zeros(self.max_bins)\n",
    "        for h, w in zip(self.histograms, self.weights):\n",
    "            result += w * h\n",
    "        return result\n",
    "\n",
    "# WL subtree extraction\n",
    "def wl_subtree_features(graph, k=2):\n",
    "    node_labels = nx.get_node_attributes(graph, 'label')\n",
    "    features = {node: [node_labels.get(node, 'N/A')] for node in graph.nodes()}\n",
    "    current_labels = node_labels.copy()\n",
    "    for _ in range(k):\n",
    "        new_labels = {}\n",
    "        for node in graph.nodes():\n",
    "            neighbors = sorted(\n",
    "                [str(current_labels.get(nbr, '')) for nbr in graph.predecessors(node)] +\n",
    "                [str(current_labels.get(nbr, '')) for nbr in graph.successors(node)]\n",
    "            )\n",
    "            combined = str(current_labels.get(node, '')) + \"|\" + \"|\".join(neighbors)\n",
    "            hash_label = hashlib.md5(combined.encode()).hexdigest()\n",
    "            new_labels[node] = hash_label\n",
    "            features[node].append(hash_label)\n",
    "        current_labels = new_labels\n",
    "    return features"
   ],
   "id": "282745af5a26e911"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Extracting FlexSketch vectors...\")\n",
    "flex_vectors = []\n",
    "for G in tqdm(graphs, desc=\"Vectorizing\"):\n",
    "    wl_feats = wl_subtree_features(G, k=3)\n",
    "    all_labels = []\n",
    "    for lbls in wl_feats.values():\n",
    "        all_labels.extend(lbls)\n",
    "    sketch = FlexSketch(max_bins=100)\n",
    "    sketch.update(Counter(all_labels))\n",
    "    flex_vectors.append(sketch.estimate_vector())\n",
    "\n"
   ],
   "id": "2e49dc3804e32598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = np.array(flex_vectors)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(\"Splitting benign and attack samples...\")\n",
    "X_benign = X[y == \"benign\"]\n",
    "X_attack = X[y == \"attack\"]\n",
    "X_attack = rd.choices(X_attack, k = 50)\n",
    "y_attack = [\"attack\"] * 50\n",
    "\n",
    "X = np.concatenate([X_benign, X_attack], axis=0)\n",
    "y = [\"benign\"] * 500 + [\"attack\"] * 50\n",
    "print(\"Standardizing feature vectors...\")\n",
    "scaler = StandardScaler()\n",
    "X_benign_scaled = scaler.fit_transform(X_benign)\n",
    "#X_attack_scaled = scaler.transform(X_attack)\n",
    "X_all_scaled = scaler.transform(X)\n",
    "\n",
    "print(\"Training KMeans on benign samples...\")\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_benign_scaled)\n",
    "\n",
    "def min_distance(x):\n",
    "    return np.min(np.linalg.norm(kmeans.cluster_centers_ - x, axis=1))\n",
    "\n",
    "print(\"Computing anomaly threshold...\")\n",
    "benign_dists = [min_distance(x) for x in tqdm(X_benign_scaled, desc=\"Benign distances\")]\n",
    "threshold = np.percentile(benign_dists, 98.5)\n",
    "\n",
    "print(\"Predicting anomalies...\")\n",
    "all_labels = [1 if cls == \"attack\" else 0 for cls in y]\n",
    "pred_labels = [1 if min_distance(x) > threshold else 0 for x in tqdm(X_all_scaled, desc=\"Predicting\")]\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "report = classification_report(all_labels, pred_labels, target_names=[\"Benign\", \"Attack\"], output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Filter only Benign, Attack\n",
    "plot_data = df_report.loc[[\"Benign\", \"Attack\"], [\"precision\", \"recall\", \"f1-score\"]]\n",
    "\n",
    "# Plot\n",
    "ax = plot_data.plot(kind=\"bar\", figsize=(10, 6), colormap='viridis', edgecolor='black')\n",
    "plt.title(\"Precision, Recall, F1-score by Class\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model_path = \"kmeans_model.joblib\"\n",
    "scaler_path = \"scaler.joblib\"\n",
    "\n",
    "joblib.dump(kmeans, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(\"\\n=== Classification Report (Anomaly Detection) ===\")\n",
    "print(report)\n",
    "# Reduce to 2D using PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X_all_scaled)\n",
    "centroids_2d = pca.transform(kmeans.cluster_centers_)\n",
    "\n",
    "# Predict cluster labels for visualization\n",
    "cluster_labels = kmeans.predict(X_all_scaled)\n",
    "\n",
    "# Plot clusters with centroids\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=cluster_labels, cmap=\"tab10\", alpha=0.6, label=\"Data Points\")\n",
    "plt.scatter(centroids_2d[:, 0], centroids_2d[:, 1], c='yellow', marker='X', s=200, edgecolor='black', label=\"Centroids\")\n",
    "\n",
    "# Annotate centroids\n",
    "for i, (x, y) in enumerate(centroids_2d):\n",
    "    plt.text(x, y, f'C{i}', fontsize=10, ha='center', va='center', weight='bold', color='black')\n",
    "\n",
    "plt.title(\"KMeans Clustering with Centroids (PCA 2D Projection)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7a88b2e9b84b9fa1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
